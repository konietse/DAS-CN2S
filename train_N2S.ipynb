{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import h5py\n",
    "\n",
    "import data\n",
    "import masks\n",
    "import inference\n",
    "import models\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 4\n",
    "fs = 50.0   \n",
    "\n",
    "nx = 11\n",
    "nx_width = 1\n",
    "if dx == 4:\n",
    "    nx = 44\n",
    "    nx_width = 4\n",
    "nt = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './data/preprocessed/real_test/'\n",
    "test_paths = sorted([test_path + f for f in os.listdir(test_path)])\n",
    "\n",
    "indices = [6250,6750,6250,5250,7250,5500]\n",
    "test_data = []\n",
    "for i, (p, idx) in enumerate(zip(test_paths, indices)):\n",
    "    with h5py.File(p, 'r') as hf:\n",
    "        DAS_sample = hf['DAS'][81:,idx-1024:idx+1024]\n",
    "        if dx == 20:\n",
    "            DAS_sample = DAS_sample[::5]\n",
    "        test_data.append(DAS_sample)\n",
    "test_data = np.stack(test_data)[[2,3,5,0,1,4]]\n",
    "\n",
    "gutter = 100\n",
    "test_data = np.pad(test_data, ((0,0),(0,0),(gutter,gutter)), mode='constant', constant_values=0)\n",
    "test_data = data.bandpass(test_data, low=1.0, high=10.0, fs=50, gutter=gutter)\n",
    "test_scale = test_data.std(axis=-1, keepdims=True)\n",
    "test_data /= test_scale\n",
    "\n",
    "test_data = torch.from_numpy(test_data.copy())\n",
    "test_scale = torch.from_numpy(test_scale.copy())\n",
    "\n",
    "fig, axs = plt.subplots(6, 1, sharex=True, sharey=True, figsize=(6,12))\n",
    "for i in range(6):\n",
    "    axs[i].imshow(test_data[i].numpy(), origin='lower', interpolation='antialiased', cmap='seismic', aspect='auto', vmin=-1, vmax=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(model, x, loss_fn, hist, optimizer=None):\n",
    "    sample, eq, noise, scale, amp = x\n",
    "    sample = sample.float().to(device)\n",
    "    \n",
    "    loss, out, target_mask, center_mask = loss_fn(model, sample)\n",
    "    \n",
    "    if optimizer is not None:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    hist['loss'].append(loss.item())\n",
    "    \n",
    "\n",
    "def train(model, dloader, loss_fn, optimizer, nx, nt, nx_width, n_epochs=50, testdata=None, name=\"\"):\n",
    "    \n",
    "    pbar0 = tqdm(range(n_epochs), position=0)\n",
    "    for epoch in pbar0:\n",
    "        pbar1 = tqdm(dloader['train'], position=1)\n",
    "        train_hist = {'loss': []}\n",
    "        model.train()\n",
    "        for x in pbar1:\n",
    "            step(model, x, loss_fn, train_hist, optimizer)\n",
    "            pbar1.set_description('[train] loss: {:.6f}'.format(train_hist['loss'][-1]))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_hist = {'loss': []}\n",
    "\n",
    "            for x in dloader['test']:\n",
    "                step(model, x, loss_fn, val_hist)\n",
    "        \n",
    "            pbar0.set_description('[val] loss: {:.6f}'.format(np.mean(val_hist['loss'])))\n",
    "\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                if name != \"\":\n",
    "                    torch.save(model.state_dict(), './ckpt/'+name+'_{:03d}.pt'.format(epoch+1))\n",
    "                if (epoch + 1) % 50 == 0:\n",
    "                    if testdata is not None:\n",
    "                        fig, axs = plt.subplots(6, 2, sharex=True, figsize=(8,12))\n",
    "                        for i, tdata in enumerate(testdata):\n",
    "                            if dx == 4:\n",
    "                                out = inference.xreconstruct(model, tdata, nx, nt, nx_width, batch_size=128, ende=True)\n",
    "                            else:\n",
    "                                out = inference.channelwise_reconstruct(model, tdata, nx, nt, batch_size=128)\n",
    "                            out = out.detach().cpu()\n",
    "                            axs[i,0].imshow(tdata.numpy(), origin='lower', interpolation='antialiased', cmap='seismic', aspect='auto', vmin=-1, vmax=1)\n",
    "                            axs[i,1].imshow(out.numpy(), origin='lower', interpolation='antialiased', cmap='seismic', aspect='auto', vmin=-1, vmax=1)\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_train = torch.from_numpy(np.load('./data/preprocessed/SIS-rotated_train_50Hz.npy'))\n",
    "eq_train /= eq_train.std(dim=-1, keepdim=True)\n",
    "eq_test = torch.from_numpy(np.load('./data/preprocessed/SIS-rotated_test_50Hz.npy'))\n",
    "eq_test /= eq_test.std(dim=-1, keepdim=True)\n",
    "\n",
    "samples_per_epoch = 10_000\n",
    "\n",
    "trainset = data.SyntheticNoiseDAS(eq_train, nx=nx, nt=nt, dx=dx, size=samples_per_epoch)\n",
    "testset = data.SyntheticNoiseDAS(eq_test, nx=nx, nt=nt, dx=dx, size=samples_per_epoch//10)\n",
    "\n",
    "batch_size = 32\n",
    "dloader = {'train': DataLoader(trainset, batch_size=batch_size, shuffle=True), \n",
    "           'test': DataLoader(testset, batch_size=batch_size, shuffle=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.N2SUNet(1, 1, 4).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def loss_fn(model, x):\n",
    "    mask = masks.channelwise_mask(x, nx_width)\n",
    "\n",
    "    out = model(x * mask)\n",
    "    loss = torch.mean(torch.mean((1-mask) * (out - x)**2, dim=-1))\n",
    "    return loss, out, mask, mask\n",
    "\n",
    "name = \"N2S-synthetic{}\".format(dx) + \"-{:d}x{:d}-{:d}x{:d}\".format(nx, nt, nx_width, 2048)\n",
    "train(model, dloader, loss_fn, optimizer, nx=nx, nt=nt, nx_width=nx_width, \n",
    "      n_epochs=200, testdata=test_data, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(model, x, loss_fn, hist, optimizer=None):\n",
    "    sample = x\n",
    "    sample = sample.float().to(device)\n",
    "    \n",
    "    loss, out, target_mask, center_mask = loss_fn(model, sample)\n",
    "    \n",
    "    if optimizer is not None:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    hist['loss'].append(loss.item())\n",
    "    \n",
    "\n",
    "def train(model, dloader, loss_fn, optimizer, nx, nt, nx_width, n_epochs=50, testdata=None, name=\"\"):\n",
    "    \n",
    "    pbar0 = tqdm(range(n_epochs), position=0)\n",
    "    for epoch in pbar0:\n",
    "        pbar1 = tqdm(dloader['train'], position=1)\n",
    "        train_hist = {'loss': []}\n",
    "        model.train()\n",
    "        for x in pbar1:\n",
    "            step(model, x, loss_fn, train_hist, optimizer)\n",
    "            pbar1.set_description('[train] loss: {:.6f}'.format(train_hist['loss'][-1]))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_hist = {'loss': []}\n",
    "\n",
    "            for x in dloader['test']:\n",
    "                step(model, x, loss_fn, val_hist)\n",
    "        \n",
    "            pbar0.set_description('[val] loss: {:.6f}'.format(np.mean(val_hist['loss'])))\n",
    "\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                if name != \"\":\n",
    "                    torch.save(model.state_dict(), './ckpt/'+name+'_{:03d}.pt'.format(epoch+1))\n",
    "                if (epoch + 1) % 50 == 0:\n",
    "                    if testdata is not None:\n",
    "                        fig, axs = plt.subplots(6, 2, sharex=True, figsize=(8,12))\n",
    "                        for i, tdata in enumerate(testdata):\n",
    "                            if dx == 4:\n",
    "                                out = inference.xreconstruct(model, tdata, nx, nt, nx_width, batch_size=128, ende=True)\n",
    "                            else:\n",
    "                                out = inference.channelwise_reconstruct(model, tdata, nx, nt, batch_size=128)\n",
    "                            out = out.detach().cpu()\n",
    "                            axs[i,0].imshow(tdata.numpy(), origin='lower', interpolation='antialiased', cmap='seismic', aspect='auto', vmin=-1, vmax=1)\n",
    "                            axs[i,1].imshow(out.numpy(), origin='lower', interpolation='antialiased', cmap='seismic', aspect='auto', vmin=-1, vmax=1)\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './data/preprocessed/real_train/'\n",
    "test_path = './data/preprocessed/real_test/'\n",
    "train_paths = sorted([train_path + f for f in os.listdir(train_path)])\n",
    "test_paths = sorted([test_path + f for f in os.listdir(test_path)])\n",
    "\n",
    "train_real_data = []\n",
    "for i, p in enumerate(train_paths):\n",
    "    with h5py.File(p, 'r') as hf:\n",
    "        DAS_sample = hf['DAS'][81:]\n",
    "        if dx == 20:\n",
    "            DAS_sample = DAS_sample[::5]\n",
    "        train_real_data.append(DAS_sample)\n",
    "train_real_data = np.stack(train_real_data)\n",
    "gutter = 1000\n",
    "train_real_data = np.pad(train_real_data, ((0,0),(0,0),(gutter,gutter)), mode='constant', constant_values=0)\n",
    "chunks = np.array_split(train_real_data, 10)\n",
    "processed_chunks = [data.bandpass(chunk, low=1.0, high=10.0, fs=fs, gutter=gutter) for chunk in chunks]\n",
    "train_real_data_processed = np.concatenate(processed_chunks, axis=0)\n",
    "train_real_data /= train_real_data.std(axis=-1, keepdims=True)\n",
    "\n",
    "test_real_data = []\n",
    "for i, p in enumerate(test_paths):\n",
    "    with h5py.File(p, 'r') as hf:\n",
    "        DAS_sample = hf['DAS'][81:]\n",
    "        if dx == 20:\n",
    "            DAS_sample = DAS_sample[::5]\n",
    "        test_real_data.append(DAS_sample)\n",
    "test_real_data = np.stack(test_real_data)\n",
    "gutter = 1000\n",
    "test_real_data = np.pad(test_real_data, ((0,0),(0,0),(gutter,gutter)), mode='constant', constant_values=0)\n",
    "chunks = np.array_split(test_real_data, 5)\n",
    "processed_chunks = [data.bandpass(chunk, low=1.0, high=10.0, fs=fs, gutter=gutter) for chunk in chunks]\n",
    "test_real_data = np.concatenate(processed_chunks, axis=0)\n",
    "test_real_data /= test_real_data.std(axis=-1, keepdims=True)\n",
    "\n",
    "trainset = data.RealDAS(train_real_data, nx=nx, nt=nt, size=samples_per_epoch)\n",
    "testset = data.RealDAS(test_real_data, nx=nx, nt=nt, size=samples_per_epoch//10)\n",
    "\n",
    "batch_size = 32\n",
    "dloader = {'train': DataLoader(trainset, batch_size=batch_size, shuffle=True), \n",
    "           'test': DataLoader(testset, batch_size=batch_size, shuffle=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.N2SUNet(1, 1, 4).to(device)\n",
    "model.load_state_dict(torch.load('./ckpt/' + \"N2S-synthetic{}\".format(dx) + \"-{:d}x{:d}-{:d}x{:d}_200.pt\".format(nx, nt, nx_width, 2048)))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def loss_fn(model, x):\n",
    "    mask = masks.channelwise_mask(x, nx_width)\n",
    "\n",
    "    out = model(x * mask)\n",
    "    loss = torch.mean(torch.mean((1-mask) * (out - x)**2, dim=-1))\n",
    "    return loss, out, mask, mask\n",
    "\n",
    "name = \"N2S-finetuned{}\".format(dx) + \"-{:d}x{:d}-{:d}x{:d}\".format(nx, nt, nx_width, 2048)\n",
    "train(model, dloader, loss_fn, optimizer, nx=nx, nt=nt, nx_width=nx_width, \n",
    "      n_epochs=200, testdata=test_data, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
